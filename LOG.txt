Week 45:
Thursday: 
    Read introductory paper (ProbVLM: Probabilistic Adapter for Frozen Vision-Language Models).
    Kick off meeting. 

Friday: 
    Set up of git and slack for communication. Started reading follow up paper (A review of uncertainty 
    quantification in deep learning: Techniques applications and challenges). Created report template. Started 
    creating presentation regarding summary of the introductory papers for meeting next Wednesday.

Week 46:
Monday: 
    Finished the presentation summarizing the papers. Started structuring what to mention in what sections in the report.

Tuesday: 
    Started writing introduction and theory in the report. 

Wednesday:	
    Meeting with Prashant where we presented the two papers mentioned above and discussed what we want to research more about.
    Need to decide if we e.g. want to do benchmark testing or/and see if we can both find the epistemic uncertainty from the deterministic 
    embeddings and also find the aleatoric uncertainty from the data and in which field we want to focus, continue on CLIP or try to find 
    uncertainties in e.g. healthcare. 

Thursday:
    Continue reading on related papers regarding choice of adapter. Looking into how to 
    separate aleatoric and epistemic uncertainties. Looking in to the Bayes By Backprop (BBB)
    adapter and how it could be implemented for the CLIP model. Looking into the ProbVLM code
    to understand how it works. Preparing questions and suggestions on how to move the project
    forward for a meeting with Prashant and Li tomorrow.

Friday:
    Meeting with Prashant and Li. Discussing how aleatoric and epistemic uncertainties work and 
    can be separated. Discussing the choice of adapter. Decided that we should start by implementing 
    the BBB BN. A second step would be to implement a separate term for the aleatoric uncertainty
    if the ProbVLM approach seems inadequate. Further down the line a benchmark against the ProbVLM
    approach would be implemented and visualizations with attention instead of diffusion.

    Preparing the Alvis environment and begin looking into how to implement the BBB. Looking into
    Bayesian Network layers using PyTorch.

Week 47:
Monday: 
    Preparing the alvis environment. Configuring VPN, and getting familiar with alvis.  
    Implementing a simple BNN as a proof of concept.

Tuesday:
    Downloading the COCO datasets to train the CLIP and ProbVLM model. Configuring the file structures and the datasets.
    Preparing a script that can be run as a batch job.
    Since downloading, extracting and moving the data to the cluster takes a long time we decided to write on the report
    and try submitting the batch job tomrorrow, so the data can load over the night.

    On evening data was finished loaded so bash files were made for creating the vocab (done) and 
    for training a simple BBB implementation (not done, some small errors for import errors).

Wednesday:


Thursday:


Friday:

